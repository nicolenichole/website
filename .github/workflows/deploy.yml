name: Deploy to GitHub Pages and AWS

on:
  push:
    branches:
      - main
      - master
  workflow_dispatch:

# OIDC requires these permissions
permissions:
  id-token: write   # Required for OIDC authentication
  contents: write   # Required for GitHub Pages deployment
  pages: write      # Required for GitHub Pages deployment

jobs:
  # Deploy to GitHub Pages
  deploy-github-pages:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    permissions:
      contents: write
      pages: write
      id-token: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build for GitHub Pages
        run: |
          export VITE_BASE_PATH="/website/"
          export VITE_OUT_DIR="docs"
          npm run build
          
          # Verify .nojekyll file exists (should be created by Vite plugin)
          if [ -f "docs/.nojekyll" ]; then
            echo ".nojekyll file exists"
          else
            echo "WARNING: .nojekyll file missing, creating it..."
            touch docs/.nojekyll
          fi
          
          # Debug: List what was built
          echo ""
          echo "=== GitHub Pages Build Output ==="
          echo "Files in docs/:"
          find docs -type f | sort
          echo ""
          echo "=== Checking for required files ==="
          echo ""
          echo "HTML files:"
          ls -la docs/*.html 2>&1 | wc -l && echo "HTML files present" || echo "HTML files missing"
          echo ""
          echo "Images folder:"
          if [ -d "docs/images" ]; then
            ls -la docs/images/ | head -8
            echo "images/ folder present ($(ls docs/images/ | wc -l) files)"
          else
            echo "images/ folder missing"
          fi
          echo ""
          echo "Styles:"
          if [ -f "docs/styles.css" ]; then
            echo "styles.css present ($(wc -c < docs/styles.css) bytes)"
          else
            echo "styles.css missing"
          fi
          echo ""
          echo "Scripts:"
          if [ -f "docs/script.js" ]; then
            echo "script.js present ($(wc -c < docs/script.js) bytes)"
          else
            echo "script.js missing"
          fi
          echo ""
          echo "Models folder:"
          if [ -d "docs/models" ]; then
            find docs/models -type f
            echo "models/ folder present"
          else
            echo "models/ folder missing"
          fi
          echo ""
          echo "Assets folder:"
          if [ -d "docs/assets" ]; then
            ls -la docs/assets/ | head -5
            echo "assets/ folder present"
          else
            echo "assets/ folder missing"
          fi
          echo ""
          echo ".nojekyll file:"
          if [ -f "docs/.nojekyll" ]; then
            echo ".nojekyll file present (Jekyll disabled)"
          else
            echo ".nojekyll file missing"
          fi
          echo ""

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: './docs'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

  # Deploy to AWS S3
  deploy-aws:
    runs-on: ubuntu-latest
    needs: deploy-github-pages
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build for AWS
        run: |
          export VITE_BASE_PATH=""
          export VITE_OUT_DIR="dist"
          npm run build
          
      - name: List build output
        run: |
          echo "Build output contents:"
          ls -la dist/ || echo "dist folder not found"
          echo ""
          echo "Files in dist:"
          find dist -type f | sort
          echo ""
          echo "Checking for HTML files:"
          ls -la dist/*.html 2>&1 || echo "No HTML files found"
          echo ""
          echo "Checking for styles and scripts:"
          ls -la dist/*.css dist/*.js 2>&1 || echo "No CSS/JS files found"

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ secrets.AWS_REGION || 'us-east-1' }}

      - name: Deploy to S3
        run: |
          # Debug: Show bucket name being used
          echo "Using bucket: ${{ secrets.AWS_S3_BUCKET }}"
          echo "Using region: ${{ secrets.AWS_REGION || 'us-east-1' }}"
          
          # Check if bucket exists
          if aws s3 ls "s3://${{ secrets.AWS_S3_BUCKET }}" 2>&1 | grep -q 'NoSuchBucket'; then
            echo "Bucket does not exist. Creating..."
            aws s3 mb "s3://${{ secrets.AWS_S3_BUCKET }}" --region ${{ secrets.AWS_REGION || 'us-east-1' }}
          fi

          # Configure static website hosting
          aws s3 website "s3://${{ secrets.AWS_S3_BUCKET }}" \
            --index-document index.html \
            --error-document index.html

          # Disable Block Public Access settings (required for public bucket policy)
          echo "Disabling Block Public Access settings..."
          aws s3api put-public-access-block \
            --bucket "${{ secrets.AWS_S3_BUCKET }}" \
            --public-access-block-configuration \
            "BlockPublicAcls=false,IgnorePublicAcls=false,BlockPublicPolicy=false,RestrictPublicBuckets=false" || \
          echo "Warning: Could not disable Block Public Access (may already be disabled or insufficient permissions)"

          # Set bucket policy for public read access
          cat > /tmp/bucket-policy.json <<EOF
          {
            "Version": "2012-10-17",
            "Statement": [
              {
                "Sid": "PublicReadGetObject",
                "Effect": "Allow",
                "Principal": "*",
                "Action": "s3:GetObject",
                "Resource": "arn:aws:s3:::${{ secrets.AWS_S3_BUCKET }}/*"
              }
            ]
          }
          EOF
          aws s3api put-bucket-policy \
            --bucket "${{ secrets.AWS_S3_BUCKET }}" \
            --policy file:///tmp/bucket-policy.json

          # Upload all files with appropriate cache settings
          # First pass: upload non-HTML, non-JSON files with long cache
          aws s3 sync dist "s3://${{ secrets.AWS_S3_BUCKET }}" \
            --delete \
            --cache-control "public, max-age=31536000, immutable" \
            --exclude "*.html" \
            --exclude "*.json"
          
          # Second pass: upload HTML and JSON files with short cache (NO --delete to avoid removing other files)
          aws s3 sync dist "s3://${{ secrets.AWS_S3_BUCKET }}" \
            --cache-control "public, max-age=0, must-revalidate" \
            --include "*.html" \
            --include "*.json"
          
          # Verify uploads
          echo "Verifying uploaded files:"
          aws s3 ls "s3://${{ secrets.AWS_S3_BUCKET }}/" --recursive | head -30

          # Set correct content types for GLB/GLTF files
          aws s3 cp dist "s3://${{ secrets.AWS_S3_BUCKET }}" \
            --recursive \
            --exclude "*" \
            --include "*.glb" \
            --content-type "model/gltf-binary" \
            --cache-control "public, max-age=31536000, immutable" || true

          aws s3 cp dist "s3://${{ secrets.AWS_S3_BUCKET }}" \
            --recursive \
            --exclude "*" \
            --include "*.gltf" \
            --content-type "model/gltf+json" \
            --cache-control "public, max-age=31536000, immutable" || true

      - name: Invalidate CloudFront cache
        run: |
          if [ -n "${{ secrets.AWS_CLOUDFRONT_ID }}" ]; then
            INVALIDATION_ID=$(aws cloudfront create-invalidation \
              --distribution-id "${{ secrets.AWS_CLOUDFRONT_ID }}" \
              --paths "/*" \
              --query 'Invalidation.Id' \
              --output text)
            echo "CloudFront invalidation created: $INVALIDATION_ID"
          else
            echo "Skipping CloudFront invalidation (AWS_CLOUDFRONT_ID not set)"
          fi

      - name: Deployment summary
        run: |
          echo "## Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "- GitHub Pages deployment completed" >> $GITHUB_STEP_SUMMARY
          echo "- AWS S3 deployment completed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Website URLs:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**GitHub Pages:**" >> $GITHUB_STEP_SUMMARY
          echo "https://${{ github.repository_owner }}.github.io/website/" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**AWS S3:**" >> $GITHUB_STEP_SUMMARY
          echo "http://${{ secrets.AWS_S3_BUCKET }}.s3-website-${{ secrets.AWS_REGION || 'us-east-1' }}.amazonaws.com" >> $GITHUB_STEP_SUMMARY
          CLOUDFRONT_ID="${{ secrets.AWS_CLOUDFRONT_ID }}"
          if [ -n "$CLOUDFRONT_ID" ]; then
            echo "- CloudFront cache invalidated" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**CloudFront (HTTPS):**" >> $GITHUB_STEP_SUMMARY
            echo "https://$(aws cloudfront get-distribution --id "$CLOUDFRONT_ID" --query 'Distribution.DomainName' --output text)" >> $GITHUB_STEP_SUMMARY
          fi

